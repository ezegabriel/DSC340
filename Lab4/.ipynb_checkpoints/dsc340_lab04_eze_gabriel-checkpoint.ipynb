{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25a07832-d2ed-4732-8cd1-c0b1d751c351",
   "metadata": {},
   "source": [
    "# Lab 4: Dry Beans Classification\n",
    "\n",
    "## Objectives\n",
    "**The purpose of this lab is to gain knowledge training and evaluating multiple models for a classification problem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd97b6fe-d5a7-473c-bdc4-e6910a49f5cf",
   "metadata": {},
   "source": [
    "\n",
    "Gabriel Eze\n",
    "\n",
    "Nolan Johnson\n",
    "\n",
    "DSC 340 S25\n",
    "\n",
    "Lab 4: Dry Beans Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bac9d3-8241-4f78-b215-08a2e94ce758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a81716b-b84a-4e12-b74b-c6b70c159fff",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421e4b9a-47c3-4f1e-9a33-7f663c6813ea",
   "metadata": {},
   "source": [
    "Read in the file by calling the absolute file path of the dataset from the work environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b36d8bd-3962-4768-b89f-b1eae453dff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_file = pd.read_excel('C:/Users/HP/OneDrive/Desktop/DSC 340/labs/Lab4/DryBeanDataset/Dry_Bean_Dataset.xlsx')\n",
    "f_file\n",
    "# f_file.info() # Check for missing data\n",
    "# f_file.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecb972e-042e-4ffd-89bb-6b5ee804d278",
   "metadata": {},
   "source": [
    "Using the histplot function from the seaborn library, we can plot the density distribution of the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8421e76-c115-4b61-b67c-cdff7b6998f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "plt.figure(figsize = (9, 5))\n",
    "sns.histplot(x = 'Class', data = f_file, stat = 'density', kde = True)\n",
    "plt.title('Density Plot for Classes')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Inspect possible outliers\n",
    "plt.figure(figsize = (9, 5))\n",
    "sns.violinplot(x = 'Class', y = 'ShapeFactor1', data = f_file)\n",
    "plt.title('ShapeFactor1 Distribution by Bean Type')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (9, 5))\n",
    "sns.violinplot(x = 'Class', y = 'Area', data = f_file)\n",
    "plt.title('Area Distribution by Bean Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfdbae8-b194-4bab-8f12-1034e35fd6a1",
   "metadata": {},
   "source": [
    "Furthermore, using the hist function from the pandas library, we can produce a tally distribution plot for all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63b1b35-6064-4790-96f3-599c834c3aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_numeric_features = f_file.select_dtypes(exclude=object) # Extract numeric portion of dataset\n",
    "\n",
    "f_numeric_features.hist(figsize = (15, 10), bins = 20) \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0254e0-a6f2-44be-b3cc-0aec66da2a2f",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ca00e6-33e1-4eea-bfb2-b36c5d3fef6c",
   "metadata": {},
   "source": [
    "Prepare data for model building by encoding categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fdf3a4-9b03-4ada-81fc-c8bb0fe33994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dataframe\n",
    "f_file.drop_duplicates()\n",
    "\n",
    "# Encode class labels mutated as 'Class_encoded' variable\n",
    "f_file['Class_encoded'] = LabelEncoder().fit_transform(f_file['Class'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae7594a-63e2-4374-8944-4338257a0680",
   "metadata": {},
   "source": [
    "Perform train-test split by stratified sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ef2a6b-61e9-49c3-be9a-079759451f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect variables\n",
    "X = f_file.drop(columns = ['Class', 'Class_encoded']) # Features\n",
    "y = f_file['Class_encoded'] # Target\n",
    "\n",
    "# Perform split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, stratify = y, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c202c20-31e8-40e2-ba63-52436003ddbf",
   "metadata": {},
   "source": [
    "## Pipeline tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c464ee-a2a7-4da0-a7fe-5821bcad8430",
   "metadata": {},
   "source": [
    "Define pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640e8087-35d5-4567-b5f5-bb82a3ca8ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pipelines = {\n",
    "    'knn' : Pipeline([('scaler', StandardScaler()), ('classifier', KNeighborsClassifier())]),\n",
    "    'logistic_regression' : Pipeline([('scaler', StandardScaler()), ('classifier', LogisticRegression(max_iter = 1000))]),\n",
    "    'decision_tree' : Pipeline([('scaler', StandardScaler()), ('classifier', DecisionTreeClassifier(random_state = 0))]),\n",
    "    'random_forest' : Pipeline([('scaler', StandardScaler()), ('classifier', RandomForestClassifier())]),\n",
    "    'svm' : Pipeline([('scaler', StandardScaler()), ('classifier', SVC())])\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea69d0f-6092-471f-add4-a5ce92889196",
   "metadata": {},
   "source": [
    "## Gridsearch with K-fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf00c2d-c03a-4907-9ed2-98948efaca3d",
   "metadata": {},
   "source": [
    "Define parameter grid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c369b536-7996-4fd5-97ed-7981582e3697",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_params = {\n",
    "    'knn' : {'classifier__n_neighbors' : range(4, 7), \n",
    "            'classifier__weights' : ['distance', 'uniform']  \n",
    "            },\n",
    "    'logistic_regression' : {'classifier__C' : [.1, 10], \n",
    "                            'classifier__solver' : ['liblinear', 'lbfgs'],\n",
    "                            'classifier__random_state' : [0] \n",
    "                            },\n",
    "    'decision_tree' : {'classifier__max_leaf_nodes' : [5, None],\n",
    "                       'classifier__max_depth' : [3, 4, 13],\n",
    "                       'classifier__min_samples_split' : [2, 4, 8],\n",
    "                       'classifier__min_samples_leaf' : [1, 3, 7]\n",
    "                       },\n",
    "    'random_forest' : {'classifier__n_estimators' : [3, 10, 30], \n",
    "                      'classifier__max_depth' : [5, None],\n",
    "                      'classifier__min_samples_leaf' : [4, 15, 100], \n",
    "                      'classifier__max_leaf_nodes' : [4, 16], \n",
    "                      'classifier__random_state' : [0] \n",
    "                      }, \n",
    "    'svm' : {'classifier__C' : [.1, 1, 10], \n",
    "            'classifier__kernel' : ['linear', 'rbf'] \n",
    "            }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9340d1dc-d0b3-4dde-9dcf-72487b6a55aa",
   "metadata": {},
   "source": [
    "Perform Grid Search with cross-validation for each pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d2541c-44b3-4e56-befc-95bc4d0ed127",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {} # Initialize dictionary to store the best models for each classifier\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    print()\n",
    "    grid_search = GridSearchCV(pipeline, grid_params[name], cv = 4, scoring = 'accuracy', n_jobs = -1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_models[name] = grid_search.best_estimator_ # Get the best combination of model hyperparameters\n",
    "    print('Best parameters for ' + name + ': ' + str(grid_search.best_params_))\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5444ea7b-c25b-4fe8-bda7-a1d98fa35792",
   "metadata": {},
   "source": [
    "When using GridSearchCV with a k-fold cross-validation, the training data is split roughly equally into k parts. For every model hyperparameter combination in a given pipeline, the estimator is trained k times. \n",
    "\n",
    "An average of the scoring metric (accuracy score) is computed from the different folds which represents how well that hyperparameter combination performed across all folds. Once all candidates have been evaluated across all folds, GridSearchCV compares their average accuracy scores and selects the best estimator with the highest achieved aggregated score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f595924-9006-4256-a106-8d71f87205d6",
   "metadata": {},
   "source": [
    "## Evaluating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4ea338-53d3-42b9-9111-f8fb2d24babf",
   "metadata": {},
   "source": [
    "Evaluate each 'top' model on holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2425e050-6e42-40ab-8c7d-f48b0c968b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Original target class\n",
    "l_class = f_file['Class'].unique()\n",
    "l_class.sort()\n",
    "\n",
    "\n",
    "# Evaluate and compare model performances\n",
    "for name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average = 'weighted') # Aggregate F1 weighted by class support  \n",
    "    report = classification_report(y_test, y_pred, target_names = l_class)\n",
    "\n",
    "    print('\\n')\n",
    "    print(name, 'Results:')\n",
    "    print('Accuracy:', round(accuracy, 4))\n",
    "    print('F1:', round(f1, 3))\n",
    "\n",
    "    print(report)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize = (7.8, 7.8)) # Specify confusion matrix plot figure and axes size\n",
    "    cm_disp = ConfusionMatrixDisplay(cm, display_labels = l_class) \n",
    "    cm_disp.plot(ax = ax) # Plot confusion matrix unto given axis\n",
    "    \n",
    "    plt.title('Confusion Matrix (' + name + ' model on test set)')\n",
    "    plt.tight_layout() # Helps prevent further clumping\n",
    "    plt.show()\n",
    "    print()\n",
    "    if name != 'svm':\n",
    "        print('-' * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8112e09-6c5c-435d-a00b-36b7dfa9f3c6",
   "metadata": {},
   "source": [
    "Since LabelEncoder() class from the sckit-learn library works by assigning integer labels in ascending order of our string target classes, we can manually edit the integer label indexing on the classification report by referencing the target class.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa6d103-c3e4-4021-aa69-76605b79e0f3",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad01cca2-d764-422f-af87-c7f71b377134",
   "metadata": {},
   "source": [
    "For this lab, I utilized a pipeline tool with GridSearch cross-validation to train multiple classifiers for predicting dry bean species. With a limited set of hyperparameter combinations, a parallel 4-fold cross validation (three-quarters - training set, remainder - validation set) across 5 pipelines takes about a minute.\n",
    "\n",
    "Both raw accuracy and weighted F1 scores is used to determine the best model amongst the top estimators after fitting hyperparameter grids for each pipeline and evaluating them on the test set. The confusion matrix and classification report for these top performing models were analyzed to assess specific instances where the model failed to predict the correct target class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190d3ab7-3278-4dd7-b847-5adb4e7e2136",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://www.google.com/search?q=how+to+use+read+csv+to+read+a+file+in+the+same+workspace+as+the+program+and+file+with+the+csv+file+a+matrix+of+header+and+values+jupyter&oq=how+to+use+read+csv+to+read+a+file+in+the+same+workspace+as+the+program+and+file+with+the+csv+file+a+matrix+of+header+and+values+jupyter&gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBCTQxODU2ajBqN6gCALACAA&sourceid=chrome&ie=UTF-8\n",
    "\n",
    "https://www.google.com/search?q=how+to+plot+a+density+plot+for+a+categorical+class+distribution+jupyter&sca_esv=71ecfd477e9beca5&sxsrf=AHTn8zqy9p7vNevOSRcyVPv1curowy2APA%3A1743701603457&ei=Y8buZ_zOG4-Ew8cPksmXmAI&ved=0ahUKEwi8jKzVsryMAxUPwvACHZLkBSMQ4dUDCBA&uact=5&oq=how+to+plot+a+density+plot+for+a+categorical+class+distribution+jupyter&gs_lp=Egxnd3Mtd2l6LXNlcnAiR2hvdyB0byBwbG90IGEgZGVuc2l0eSBwbG90IGZvciBhIGNhdGVnb3JpY2FsIGNsYXNzIGRpc3RyaWJ1dGlvbiBqdXB5dGVySPGeAVCyA1jcmAFwAngBkAEAmAGXAaAB6xaqAQQyOC42uAEDyAEA-AEBmAIGoALgA8ICChAAGLADGNYEGEfCAgcQIxiwAhgnwgIFEAAY7wXCAggQABiABBiiBMICBBAhGAqYAwCIBgGQBgiSBwM0LjKgB4VCsgcDMi4yuAfIAw&sclient=gws-wiz-serp\n",
    "\n",
    "https://www.google.com/search?q=easiest+way+to+extract+by+columns+numeric+data+jupyter&oq=easiest+way+to+extract+by+columns+numeric+data+jupyter&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRigAdIBCTE2Mzc2ajBqN6gCALACAA&sourceid=chrome&ie=UTF-8\n",
    "\n",
    "https://stackoverflow.com/questions/23045318/grid-search-over-multiple-classifiers\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html\n",
    "\n",
    "https://www.google.com/search?q=how+to+increase+area+of+confusion+matrix+plot+so+that+display_labels+is+properly+visible&sca_esv=49c9fbd1deebda4c&sxsrf=AHTn8zrv8Gkpim8jBm_Gxyxgs_NSYXdfLg%3A1744064913845&ei=kVH0Z5qxM6b9ptQPo_CVoAI&ved=0ahUKEwjavZ6N_MaMAxWmvokEHSN4BSQQ4dUDCBI&uact=5&oq=how+to+increase+area+of+confusion+matrix+plot+so+that+display_labels+is+properly+visible&gs_lp=Egxnd3Mtd2l6LXNlcnAiWGhvdyB0byBpbmNyZWFzZSBhcmVhIG9mIGNvbmZ1c2lvbiBtYXRyaXggcGxvdCBzbyB0aGF0IGRpc3BsYXlfbGFiZWxzIGlzIHByb3Blcmx5IHZpc2libGVIAFAAWABwAHgBkAEAmAEAoAEAqgEAuAEDyAEA-AEBmAIAoAIAmAMAkgcAoAcAsgcAuAcA&sclient=gws-wiz-serp\n",
    "\n",
    "https://www.projectpro.io/recipes/optimize-hyper-parameters-of-decisiontree-model-using-grid-search-in-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
